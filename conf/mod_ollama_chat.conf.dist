#
# mod-ollama-chat Configuration File
# Updated for OpenRouter.ai Integration
#

[worldserver]

###################################################################################################
# OPENROUTER.AI CHAT MODULE CONFIGURATION
###################################################################################################

#
#    OllamaChat.Enable
#        Description: Enable or disable the OpenRouter.ai chat module
#        Default:     1 (enabled)
#

OllamaChat.Enable = 1

#
#    OllamaChat.OpenRouterApiKey
#        Description: Your OpenRouter.ai API key (REQUIRED)
#        Default:     "" (empty - must be configured)
#        Note:        Get your API key from https://openrouter.ai/keys
#

OllamaChat.OpenRouterApiKey = ""

#
#    OllamaChat.OpenRouterUrl
#        Description: OpenRouter.ai API endpoint URL
#        Default:     "https://openrouter.ai/docs/api-reference/chat-completion"
#

OllamaChat.OpenRouterUrl = "https://openrouter.ai/docs/api-reference/chat-completion"

#
#    OllamaChat.OpenRouterModel
#        Description: AI model to use from OpenRouter.ai FREE
#        Default:     "mistralai/mistral-7b-instruct:free"
#        Examples:    "mistralai/mistral-small-3.2-24b-instruct:free"
#                     "moonshotai/kimi-dev-72b:free"
#                     "deepseek/deepseek-r1-0528-qwen3-8b:free"
#                     "deepseek/deepseek-r1-0528:free"
#                     "sarvamai/sarvam-m:free"
#                     "mistralai/devstral-small:free"
#                     "google/gemma-3n-e4b-it:free"
#                     "qwen/qwen3-30b-a3b:free"
#                     "qwen/qwen3-8b:free"
#                     "qwen/qwen3-14b:free"
#                     "qwen/qwen3-32b:free"
#                     "qwen/qwen3-235b-a22b:free"
#                     "tngtech/deepseek-r1t-chimera:free"
#                     "microsoft/mai-ds-r1:free"
#                     "thudm/glm-z1-32b:free"
#                     "thudm/glm-4-32b:free"
#                     "shisa-ai/shisa-v2-llama3.3-70b:free"
#                     "arliai/qwq-32b-arliai-rpr-v1:free"
#                     "agentica-org/deepcoder-14b-preview:free"
#                     "moonshotai/kimi-vl-a3b-thinking:free"
#                     "nvidia/llama-3.3-nemotron-super-49b-v1:free"
#                     "nvidia/llama-3.1-nemotron-ultra-253b-v1:free"
#                     "meta-llama/llama-4-maverick:free"
#                     "meta-llama/llama-4-scout:free"
#                     "deepseek/deepseek-v3-base:free"
#                     "qwen/qwen2.5-vl-32b-instruct:free"
#                     "deepseek/deepseek-chat-v3-0324:free"
#                     "featherless/qwerky-72b:free"
#                     "mistralai/mistral-small-3.1-24b-instruct:free"
#                     "google/gemma-3-4b-it:free"
#                     "google/gemma-3-12b-it:free"
#                     "rekaai/reka-flash-3:free"
#                     "google/gemma-3-27b-it:free"
#                     "qwen/qwq-32b:free"
#                     "nousresearch/deephermes-3-llama-3-8b-preview:free"
#                     "cognitivecomputations/dolphin3.0-r1-mistral-24b:free"
#                     "cognitivecomputations/dolphin3.0-mistral-24b:free"
#                     "qwen/qwen2.5-vl-72b-instruct:free"
#                     "mistralai/mistral-small-24b-instruct-2501:free"
#                     "deepseek/deepseek-r1-distill-qwen-14b:free"
#                     "deepseek/deepseek-r1-distill-llama-70b:free"
#                     "deepseek/deepseek-r1:free"
#                     "deepseek/deepseek-chat:free"
#                     "google/gemini-2.0-flash-exp:free"
#                     "meta-llama/llama-3.3-70b-instruct:free"
#                     "qwen/qwen-2.5-coder-32b-instruct:free"
#                     "meta-llama/llama-3.2-1b-instruct:free"
#                     "meta-llama/llama-3.2-11b-vision-instruct:free"
#                     "qwen/qwen-2.5-72b-instruct:free"
#                     "meta-llama/llama-3.1-8b-instruct:free"
#                     "mistralai/mistral-nemo:free"
#                     "google/gemma-2-9b-it:free"
#                     "mistralai/mistral-7b-instruct:free"

OllamaChat.OpenRouterModel = "mistralai/mistral-7b-instruct:free"

#
#    OllamaChat.OpenRouterMaxTokens
#        Description: Maximum number of tokens to generate in response
#        Default:     150
#        Range:       1-4096 (depends on model)
#

OllamaChat.OpenRouterMaxTokens = 150

#
#    OllamaChat.OpenRouterTemperature
#        Description: Controls randomness in responses (0.0 = deterministic, 1.0 = very random)
#        Default:     0.7
#        Range:       0.0-2.0
#

OllamaChat.OpenRouterTemperature = 0.7

#
#    OllamaChat.OpenRouterTopP
#        Description: Controls diversity via nucleus sampling
#        Default:     0.9
#        Range:       0.0-1.0
#

OllamaChat.OpenRouterTopP = 0.9

#
#    OllamaChat.OpenRouterTopK
#        Description: Limits vocabulary to top K tokens (0 = disabled)
#        Default:     0
#        Range:       0-100
#

OllamaChat.OpenRouterTopK = 0

#
#    OllamaChat.OpenRouterSystemPrompt
#        Description: System prompt to set AI behavior and personality
#        Default:     "" (empty)
#        Example:     "You are a helpful NPC in a fantasy MMORPG world."
#

OllamaChat.OpenRouterSystemPrompt = ""

#
#    OllamaChat.OpenRouterSeed
#        Description: Seed for reproducible outputs (empty = random)
#        Default:     "" (empty)
#

OllamaChat.OpenRouterSeed = ""

#
#    OllamaChat.OpenRouterSiteUrl
#        Description: Your site URL for OpenRouter.ai tracking (optional)
#        Default:     "" (empty)
#

OllamaChat.OpenRouterSiteUrl = ""

#
#    OllamaChat.OpenRouterSiteName
#        Description: Your site name for OpenRouter.ai tracking (optional)
#        Default:     "" (empty)
#

OllamaChat.OpenRouterSiteName = ""

########################################
# mod-ollama-chat configuration
########################################

# OllamaChat.DisableRepliesInCombat
#     Description: If true, bots will not reply or produce random chatter when in combat.
#     Default:     true
OllamaChat.DisableRepliesInCombat = true

# OllamaChat.SayDistance
#     Description: The maximum distance (in game units) a bot must be within to reply on a Say message.
#     Default:     30.0
OllamaChat.SayDistance = 30.0

# OllamaChat.YellDistance
#     Description: The maximum distance (in game units) a bot must be within to reply on a Yell message.
#     Default:     100.0
OllamaChat.YellDistance = 100.0

# OllamaChat.GeneralDistance
#     Description: The maximum distance (in game units) a bot must be within to reply on a custom (SRC_GENERAL) channel.
#     Default:     600.0
OllamaChat.GeneralDistance = 600.0

# OllamaChat.PlayerReplyChance
#     Description: The percent chance (0-100) that an eligible bot replies when the sender is a player.
#     Default:     90
OllamaChat.PlayerReplyChance = 90

# OllamaChat.BotReplyChance
#     Description: The percent chance (0-100) that an eligible bot replies when the sender is an AI bot.
#     Default:     10
OllamaChat.BotReplyChance = 10

# OllamaChat.MaxBotsToPick
#     Description: The maximum number of bots that can be randomly selected to reply when no bot name is explicitly mentioned.
#     Default:     2
OllamaChat.MaxBotsToPick = 2

# OllamaChat.NumPredict
#     Description: Maximum number of tokens to generate in Ollama responses.
#     0 = unlimited. Only set if you want a hard cap.
#     Default: 40
#
#     | NumPredict | Approx. Words | Use Case                         |
#     |:----------:|:-------------:|:---------------------------------|
#     |     20     |   ~13–15      | Very short/emote/chat            |
#     |     30     |     ~20       | Short reply                      |
#     |     40     |   ~27–30      | Standard WoW reply (recommended) |
#     |     50     |   ~35–38      | Slightly longer reply            |
#     |     75     |   ~50–60      | Long quest/lore text             |
#     |    100+    |   70–80+      | Multi-paragraph (not typical)    |
OllamaChat.NumPredict = 40

# OllamaChat.Temperature
#     Description: Controls the "creativity" or randomness of the model’s output.
#                  Lower values (e.g., 0.2) = more focused, repetitive, and predictable.
#                  Higher values (e.g., 1.0) = more random, creative, or surprising.
#                  0.8 is the Ollama default.
#     Example:     OllamaChat.Temperature = 0.6
#     Default:     0.8
OllamaChat.Temperature = 0.8

# OllamaChat.TopP
#     Description: Controls nucleus sampling, another way to shape randomness.
#                  Lower values (e.g., 0.5) = more conservative.
#                  Higher values (up to 1.0) = more open.
#                  0.95 is the Ollama default.
#     Example:     OllamaChat.TopP = 0.9
#     Default:     0.95
OllamaChat.TopP = 0.95

# OllamaChat.RepeatPenalty
#     Description: Discourages repetition in model output.
#                  1.0 = no penalty. Higher (e.g., 1.2) = less repetition.
#                  1.1 is the Ollama default.
#     Example:     OllamaChat.RepeatPenalty = 1.2
#     Default:     1.1
OllamaChat.RepeatPenalty = 1.1

# OllamaChat.NumCtx
#     Description: Maximum context length (in tokens) sent to the model.
#                  0 = model default. Use a value only if you want to restrict or expand context.
#                  Example for Llama-3 8B: 8192. For 70B: 8192/32768.
#     Example:     OllamaChat.NumCtx = 4096
#     Default:     0
OllamaChat.NumCtx = 0

# OllamaChat.Stop
#     Description: Optional. Comma-separated list of string "stop sequences". If the model outputs any of these strings, it will immediately stop generating further text and return the response up to that point. Use this to prevent the model from continuing into unwanted sections, such as another user's dialogue turn in a chat application.
#                  Example: "User:,Bot:" will stop the output if "User:" or "Bot:" appears in the response. Leave blank to disable.
#     Example:     OllamaChat.Stop = User:,Bot:
#     Default:     (empty)
OllamaChat.Stop =

# OllamaChat.SystemPrompt
#     Description: Optional. Content for the "system" field sent to Ollama. Can be used to steer or "prime" the model's behavior globally.
#                  Leave blank for no system prompt, or enter your own.
#     Example:     OllamaChat.SystemPrompt = "Always answer as if you are a WoW quest giver."
#     Default:     (empty)
OllamaChat.SystemPrompt =

# OllamaChat.Seed
#     Description: Optional. Random seed for deterministic generation. Set to a number for repeatable results, or leave blank for normal random output.
#     Example:     OllamaChat.Seed = 42
#     Default:     (empty)
OllamaChat.Seed =

# OllamaChat.EnableRandomChatter
#     Description: Enable or disable random chatter from AI bots when a real player is nearby.
#     Default:     1 (true)
OllamaChat.EnableRandomChatter = 1

# OllamaChat.DebugEnabled
#     Description: Enables extra logging for debugging purposes.
#                  When set to 1 (true), detailed debug information will be logged by the module.
#                  When set to 0 (false), only standard logging is used.
#     Default:     0 (false)
OllamaChat.DebugEnabled = 0

# OllamaChat.MinRandomInterval
#     Description: The minimum time (in seconds) between random lines from an AI bot.
#     Default:     45
OllamaChat.MinRandomInterval = 45

# OllamaChat.MaxRandomInterval
#     Description: The maximum time (in seconds) between random lines from an AI bot.
#     Default:     180
OllamaChat.MaxRandomInterval = 180

# OllamaChat.EnableRPPersonalities
#     Description: Enables or disables the use of defined roleplay personalities for AI bots.
#                  When enabled (1), bots will respond with distinct personalities based on their assigned type.
#                  When disabled (0), bots will use a neutral/default response style.
#     Default:     0 (false)
OllamaChat.EnableRPPersonalities = 0

# OllamaChat.MaxConversationHistory
#     Description: The maximum number of recent message pairs (player + bot reply) to track per bot/player combination.
#                  This history is stored in memory and included in the LLM prompt when the same player talks to the bot again.
#     Default:     5
OllamaChat.MaxConversationHistory = 5

# OllamaChat.ConversationHistorySaveInterval
#     Description: The interval (in minutes) between periodic saves of conversation history from memory to the database.
#                  Set to 0 to disable auto-saving.
#     Default:     10
OllamaChat.ConversationHistorySaveInterval = 10

# OllamaChat.EnableChatHistory
#     Description: Enables or disables the use of Chat History.
#     Default:     1 (true)
OllamaChat.EnableChatHistory = 1

# OllamaChat.EnableChatBotSnapshotTemplate
#     Description: Enable or disable additional awareness context for each bot.
#                  When enabled (1), the bot will include a snapshot of its current status and surroundings in the chat prompt.
#                  This includes combat status, group info, known spells, active quests, line of sight objects, and nearby players.
#                  When disabled (0), this context is not included in the chat prompt.
#                  This is useful for bots that need to be aware of their environment and current status.
#                  Enabling this may increase the response time and token usage of the API calls.
#     Default:     0 (false)
OllamaChat.EnableChatBotSnapshotTemplate = 0

# OllamaChat.RandomChatterRealPlayerDistance
#     Description: The maximum distance (in game units) a real player must be within for random bot chatter to trigger.
#     Default:     40
OllamaChat.RandomChatterRealPlayerDistance = 40.0

# OllamaChat.RandomChatterBotCommentChance
#     Description: The percent chance (0-100) that an AI bot will add a comment when random chatter is triggered.
#     Default:     25
OllamaChat.RandomChatterBotCommentChance = 25

# OllamaChat.RandomChatterMaxBotsPerPlayer
#     Description: The maximum number of AI bots that can trigger per random chatter update when a real player is nearby.
#                  This limits how many bots can respond at once to avoid spam.
#                   Each bot can only process once per tick, no duplicates if multiple real players are close.
#     Default:     2
OllamaChat.RandomChatterMaxBotsPerPlayer = 2

# OllamaChat.BlacklistCommands
#     Description: A comma-separated list of command prefixes that should be ignored by AI bots.
#                  If a message starts with any of these prefixes, the bot will not respond.
#     Default:     
OllamaChat.BlacklistCommands = autogear,talents,reset botAI,summon,release,revive,leave,attack,follow,flee,stay,runaway,grind,disperse,give leader,spells,cast,quests,accept,drop,talk,reset,ss ,trainer,rti ,rtsc,do,ll,e,ue,nc,open,destroy,s,b,bank,gb,u,co,ELVUI_VERSIONCHK,Asked ,DPSMate_,LibGroupTalents,BLT,oRA3,Skada,HealBot,hbComms,questie,pfQuest,DBMv4-Ver,BWVQ3

# OllamaChat.MaxConcurrentQueries
#     Description: The maximum number of concurrent API queries allowed. Use 0 for no limit.
#     Default:     0
OllamaChat.MaxConcurrentQueries = 0

# OllamaChat.DefaultPersonalityPrompt
#     Description: The fallback personality description used when a bot has no specific roleplay type assigned.
#     Default:     Talk like a standard WoW player.
OllamaChat.DefaultPersonalityPrompt = "Speak like a real WoW player from Wrath. Stay in character and use casual in-game tone."

# OllamaChat.RandomChatterPromptTemplate
#   Description: The template string for random bot chatter prompts.
#   Placeholders (named): {bot_name} {bot_level} {bot_class} {bot_race} {bot_gender} {bot_role} {bot_faction} {bot_area} {bot_zone} {bot_map} {bot_personality} {environment_info}
OllamaChat.RandomChatterPromptTemplate = "You are a Wrath-era WoW player. Name: {bot_name}, Level: {bot_level} {bot_class}, {bot_race} {bot_gender}, Spec: {bot_role}, Faction: {bot_faction}. Location: {bot_area}, Zone: {bot_zone}, Map: {bot_map}. Personality: {bot_personality}. {environment_info} Reply casually in under 15 words. No quotes, markdown, symbols, or emojis. Use real WoW slang. Avoid uncommon jargon or formatting."

# OllamaChat.ChatPromptTemplate
#   Description: The main template for bot chat prompts sent to the LLM.
#   Placeholders (named): {bot_name} {bot_level} {bot_class} {bot_personality} {player_level} {player_class} {player_name} {player_message} {extra_info}
OllamaChat.ChatPromptTemplate = "You're a Wrath-era WoW player familiar with Vanilla and TBC. Name: {bot_name}, Level: {bot_level} {bot_class}, Personality: {bot_personality}. A level {player_level} {player_class} named {player_name} said: '{player_message}'. {extra_info} Reply naturally in under 15 words. Use authentic WoW tone. Respect higher levels, mock lower ones. Be blunt if provoked. Be precise if giving directions. Never contradict your class, race, or location. Never act like a narrator—just respond like a player."

# OllamaChat.ChatExtraInfoTemplate
#   Description: The context/details string about the bot and player, injected into the chat prompt as the last parameter.
#   Placeholders (named): {bot_race} {bot_gender} {bot_role} {bot_faction} {bot_guild} {bot_group_status} {bot_gold} {player_race} {player_gender} {player_role} {player_faction} {player_guild} {player_group_status} {player_gold} {player_distance} {bot_area} {bot_zone} {bot_map}
OllamaChat.ChatExtraInfoTemplate = "Your Info: {bot_race} {bot_gender}, Spec: {bot_role}, Faction: {bot_faction}, Guild: {bot_guild}, Group: {bot_group_status}, Gold: {bot_gold}. Player Info: {player_race} {player_gender}, Spec: {player_role}, Faction: {player_faction}, Guild: {player_guild}, Group: {player_group_status}, Gold: {player_gold}, Distance: {player_distance} yards. Location: {bot_area}, Zone: {bot_zone}, Map: {bot_map}. Only respond to the new message. No commentary, no meta-talk, no prefix—just the reply."

# OllamaChat.ChatHistoryHeaderTemplate
#   Description: Format for header in conversation history context.
#   Placeholders (named): {player_name}
OllamaChat.ChatHistoryHeaderTemplate = "Recent chats with {player_name}. Use only for context. Reply to the new message."

# OllamaChat.ChatHistoryLineTemplate
#   Description: Format for each line in conversation history context.
#   Placeholders (named): {player_name} {player_message} {bot_reply}
OllamaChat.ChatHistoryLineTemplate = "{player_name} said: {player_message}\nYou said: {bot_reply}\n"

# OllamaChat.ChatHistoryFooterTemplate
#   Description: Format for footer in conversation history context.
#   Placeholders (named): {player_name} {player_message}
OllamaChat.ChatHistoryFooterTemplate = "NEW MESSAGE from {player_name}: {player_message}"

# OllamaChat.ChatBotSnapshotTemplate
#   Description: The template string for the context snapshot of the bot's surroundings and status.
#   Placeholders (named): {combat} {group} {spells} {quests} {los} {players}
OllamaChat.ChatBotSnapshotTemplate = "CURRENT CONTEXT:\n{combat}\n{group}\nSpells:\n{spells}\nQuests:\n{quests}\nVisible Objects:\n{los}\nNearby Players:\n{players}"

# OllamaChat.EnvCommentCreature
#   Description: A pipe-separated (|) list of template messages for when any creature is spotted nearby.
#   Placeholders (named): {creature_name}
OllamaChat.EnvCommentCreature = You spot a creature named '{creature_name}'.

# OllamaChat.EnvCommentGameObject
#   Description: A pipe-separated (|) list of template messages for when a game object is nearby.
#   Placeholders (named): {object_name}
OllamaChat.EnvCommentGameObject = You see {object_name} nearby.

# OllamaChat.EnvCommentEquippedItem
#   Description: A pipe-separated (|) list of template messages referencing a random equipped item.
#   Placeholders (named): {item_name}
OllamaChat.EnvCommentEquippedItem = Talk about your equipped item {item_name}.

# OllamaChat.EnvCommentBagItem
#   Description: A pipe-separated (|) list of template messages for an item in the bot's bag.
#   Placeholders (named): {item_description}
OllamaChat.EnvCommentBagItem = You notice a {item_description} in your bag.

# OllamaChat.EnvCommentBagItemSell
#   Description: A pipe-separated (|) list of template messages for an item the bot might try to sell.
#   Placeholders (named): {item_count} {item_name}
OllamaChat.EnvCommentBagItemSell = You are trying persuasively to sell {item_count} of this item {item_name}.

# OllamaChat.EnvCommentSpell
#   Description: A pipe-separated (|) list of template messages about a random known spell.
#   Placeholders (named): {spell_name} {spell_effect} {spell_cost}
OllamaChat.EnvCommentSpell = Discuss possible uses or strategies for '{spell_name}', which {spell_effect} and costs {spell_cost}.

# OllamaChat.EnvCommentQuestArea
#   Description: A pipe-separated (|) list of template messages to suggest an area to quest in.
#   Placeholders (named): {quest_area}
OllamaChat.EnvCommentQuestArea = Suggest you could go questing around {quest_area}.

# OllamaChat.EnvCommentVendor
#   Description: A pipe-separated (|) list of template messages when a vendor NPC is nearby.
#   Placeholders (named): {vendor_name}
OllamaChat.EnvCommentVendor = You spot {vendor_name} selling wares nearby.

# OllamaChat.EnvCommentQuestgiver
#   Description: A pipe-separated (|) list of template messages when a questgiver NPC is nearby.
#   Placeholders (named): {questgiver_name} {quest_count}
OllamaChat.EnvCommentQuestgiver = {questgiver_name} looks like they have {quest_count} quests for anyone brave enough.

# OllamaChat.EnvCommentBagSlots
#   Description: A pipe-separated (|) list of template messages about available bag slots.
#   Placeholders (named): {bag_slots}
OllamaChat.EnvCommentBagSlots = You have {bag_slots} free bag slots left.

# OllamaChat.EnvCommentDungeon
#   Description: A pipe-separated (|) list of template messages for when the bot is in a dungeon.
#   Placeholders (named): {dungeon_name}
OllamaChat.EnvCommentDungeon = You're in a Dungeon instance named '{dungeon_name}' talk about the Dungeon or one of its Bosses.

# OllamaChat.EnvCommentUnfinishedQuest
#   Description: A pipe-separated (|) list of template messages about a random incomplete quest in the bot's log.
#   Placeholders (named): {quest_name}
OllamaChat.EnvCommentUnfinishedQuest = Say the name of and talk about your un-finished quest '{quest_name}'.
